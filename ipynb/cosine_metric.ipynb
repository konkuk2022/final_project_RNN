{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install kss"
      ],
      "metadata": {
        "id": "0SyV-SJvZlTO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08251d78-ce25-422e-e27a-28d6c628d73e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.24.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.13.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.10.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: kss in /usr/local/lib/python3.7/dist-packages (3.6.4)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from kss) (2022.6.2)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.7/dist-packages (from kss) (9.0.0)\n",
            "Requirement already satisfied: emoji==1.2.0 in /usr/local/lib/python3.7/dist-packages (from kss) (1.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBQg8vVAdKNW",
        "outputId": "1a7a2d6d-fb7a-4551-8c68-1736fa9d09fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "LABELS = ['불평/불만',\n",
        " '환영/호의',\n",
        " '감동/감탄',\n",
        " '지긋지긋',\n",
        " '고마움',\n",
        " '슬픔',\n",
        " '화남/분노',\n",
        " '존경',\n",
        " '기대감',\n",
        " '우쭐댐/무시함',\n",
        " '안타까움/실망',\n",
        " '비장함',\n",
        " '의심/불신',\n",
        " '뿌듯함',\n",
        " '편안/쾌적',\n",
        " '신기함/관심',\n",
        " '아껴주는',\n",
        " '부끄러움',\n",
        " '공포/무서움',\n",
        " '절망',\n",
        " '한심함',\n",
        " '역겨움/징그러움',\n",
        " '짜증',\n",
        " '어이없음',\n",
        " '없음',\n",
        " '패배/자기혐오',\n",
        " '귀찮음',\n",
        " '힘듦/지침',\n",
        " '즐거움/신남',\n",
        " '깨달음',\n",
        " '죄책감',\n",
        " '증오/혐오',\n",
        " '흐뭇함(귀여움/예쁨)',\n",
        " '당황/난처',\n",
        " '경악',\n",
        " '부담/안_내킴',\n",
        " '서러움',\n",
        " '재미없음',\n",
        " '불쌍함/연민',\n",
        " '놀람',\n",
        " '행복',\n",
        " '불안/걱정',\n",
        " '기쁨',\n",
        " '안심/신뢰']"
      ],
      "metadata": {
        "id": "u3u3P1SEYmim"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import ElectraConfig, ElectraModel\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class ELECTRALSTMClassification(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.device = 'cuda'\n",
        "        self.config = ElectraConfig.from_pretrained(\"beomi/KcELECTRA-base\",\n",
        "                                                    problem_type=\"multi_label_classification\",\n",
        "                                                    num_labels = 44) \n",
        "        \n",
        "        self.embedding_size = 768\n",
        "        self.batch_size = 32\n",
        "\n",
        "        self.electra = ElectraModel.from_pretrained(\"beomi/KcELECTRA-base\",config=self.config).to(self.device)\n",
        "        self.lstm = nn.LSTM(self.embedding_size, self.embedding_size, batch_first=True, bidirectional=True).to(self.device)\n",
        "        self.fc1 = nn.Linear(self.embedding_size * 5, 44)\n",
        "        self.fc2 = nn.Linear(self.embedding_size * 2, 44)\n",
        "        self.gelu = nn.GELU()\n",
        "\n",
        "\n",
        "    def forward(self, input_ids=None, attention_mask=None, sep_idx=None):\n",
        "        \n",
        "        electra_output = self.electra(input_ids, attention_mask)[0]\n",
        "\n",
        "        cls = electra_output[:, 0, :] # <CLS> embeddings\n",
        "        # sep 토큰 가져오기\n",
        "        sep_idx_x = sep_idx[0]\n",
        "        sep_idx_y = sep_idx[1]\n",
        "\n",
        "        idx = 0\n",
        "        cnt = 0\n",
        "        longest = torch.where(sep_idx_x==torch.mode(sep_idx_x).values)[0].size()[0]\n",
        "        # 초기화\n",
        "        sep_embeddings = torch.zeros(cls.size(0), longest, self.embedding_size).to(self.device)\n",
        "\n",
        "        # embedding 값 집어넣어주기\n",
        "        for x, y in zip(sep_idx_x, sep_idx_y):\n",
        "            if idx == x:\n",
        "                sep_embeddings[x, cnt, :] += electra_output[x, y, :]\n",
        "                cnt += 1\n",
        "            else:\n",
        "                idx += 1\n",
        "                cnt = 0\n",
        "                sep_embeddings[x, cnt, :] += electra_output[x, y, :]\n",
        "\n",
        "        # lstm 실행\n",
        "        lstm_output, (h, c) = self.lstm(sep_embeddings) # (batch_size, seq_length, embedding_size)\n",
        "\n",
        "        # lstm 처음과 끝 가져오기\n",
        "        sep_first = lstm_output[:, 0, :]\n",
        "        sep_last = lstm_output[:, -1, :]\n",
        "\n",
        "        # lstm 결과와 cls 토큰 합치기\n",
        "        concats = torch.cat((cls, sep_first, sep_last), dim=1)\n",
        "        # fc 레이어에 넣고 44개 output\n",
        "        x = self.gelu(concats)\n",
        "        output = self.fc1(x)\n",
        "\n",
        "        first_output = self.fc2(sep_first)\n",
        "        last_output = self.fc2(sep_last)\n",
        "\n",
        "        \n",
        "        return output, first_output, last_output"
      ],
      "metadata": {
        "id": "RaczW4EDZj7o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cos_similiarity(v1, v2):\n",
        "    dot_product = np.dot(v1, v2)\n",
        "    l2_norm = (np.sqrt(sum(np.square(v1)))*np.sqrt(sum(np.square(v2))))\n",
        "    similarity = dot_product/l2_norm\n",
        "\n",
        "    return similarity"
      ],
      "metadata": {
        "id": "yGkMIKv1cEdy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import kss\n",
        "\n",
        "def kss_sentence(sent):\n",
        "    x = ''\n",
        "    split_sent = kss.split_sentences(sent)\n",
        "    for i,s in enumerate(split_sent):\n",
        "        if i == 0:\n",
        "            x = s\n",
        "        else:\n",
        "            x += ' [SEP] ' + s\n",
        "    return x"
      ],
      "metadata": {
        "id": "x0sNGR8Vdrpa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained('beomi/KcELECTRA-base', do_lower_case=False)\n",
        "\n",
        "def embedding(text):\n",
        "    embeddings = tokenizer(text,\n",
        "                           truncation=True,\n",
        "                           max_length=512,\n",
        "                           padding=\"max_length\",\n",
        "                           return_token_type_ids=False,\n",
        "                           return_attention_mask=True,\n",
        "                           add_special_tokens=True)\n",
        "    return embeddings"
      ],
      "metadata": {
        "id": "J6RPeo9tkIsX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dic_ori = \"계절학기를 마치고 오빠와 여의나루 역에 갔다. 도착해서 빠삐코, 탱크보이 하나씩 빨아주면서 돗자리를 폈다. 쨍한 여름날씨. 가방에서 책을 꺼내 손잡고 읽기 시작했다.이렇게 평화로울수가 없었다.\"\n",
        "dic_data = kss_sentence(dic_ori)\n",
        "\n",
        "\n",
        "movie_path = '/content/drive/MyDrive/final_project/영화_52_data.pkl'\n",
        "\n",
        "movie_ori = pd.read_pickle(movie_path)\n",
        "\n",
        "dic_emb = embedding(dic_data)\n"
      ],
      "metadata": {
        "id": "bMWnLmrNa8m2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = '/content/drive/MyDrive/final_project/data_processing/best_model_52.pth'\n",
        "\n",
        "model = ELECTRALSTMClassification()\n",
        "model.load_state_dict(torch.load(PATH)['model_state_dict'],strict=False)\n",
        "model.to('cuda')"
      ],
      "metadata": {
        "id": "P9usH2u9Z_nb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b838852b-0f9a-4c83-bcb8-66a56001bd67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at beomi/KcELECTRA-base were not used when initializing ElectraModel: ['discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense_prediction.weight']\n",
            "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ELECTRALSTMClassification(\n",
              "  (electra): ElectraModel(\n",
              "    (embeddings): ElectraEmbeddings(\n",
              "      (word_embeddings): Embedding(50135, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): ElectraEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (lstm): LSTM(768, 768, batch_first=True, bidirectional=True)\n",
              "  (fc1): Linear(in_features=3840, out_features=44, bias=True)\n",
              "  (fc2): Linear(in_features=1536, out_features=44, bias=True)\n",
              "  (gelu): GELU(approximate=none)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_id = torch.LongTensor(dic_emb['input_ids']).unsqueeze(0).to('cuda')\n",
        "mask = torch.LongTensor(dic_emb['attention_mask']).unsqueeze(0).to('cuda')\n",
        "sep_idx = torch.where(input_id == 3)\n",
        " \n",
        "y_pred = model(input_id, mask, sep_idx)"
      ],
      "metadata": {
        "id": "2Uy1uV0do9n0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = torch.sigmoid(y_pred[0])[0]\n",
        "print(torch.sigmoid(y_pred[0]))\n",
        "arr = np.zeros(44)\n",
        "for i in range(44):\n",
        "    if y.tolist()[i] >= 0.3:\n",
        "        arr[i] = 1\n",
        "    else:\n",
        "        arr[i] = 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srsjRkSxtXbd",
        "outputId": "2cbcfe24-9333-4b2a-9769-dfc664c0e9fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.0439, 0.2028, 0.5314, 0.0362, 0.2874, 0.2047, 0.0095, 0.0250, 0.5479,\n",
            "         0.0197, 0.1156, 0.0580, 0.0091, 0.4463, 0.3528, 0.2080, 0.0917, 0.0249,\n",
            "         0.0083, 0.0555, 0.0126, 0.0030, 0.0433, 0.0151, 0.1810, 0.0516, 0.0239,\n",
            "         0.2902, 0.7801, 0.2125, 0.0073, 0.0039, 0.0772, 0.0383, 0.0040, 0.0286,\n",
            "         0.0797, 0.0453, 0.0204, 0.0416, 0.8634, 0.0355, 0.8710, 0.2546]],\n",
            "       device='cuda:0', grad_fn=<SigmoidBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(y.detach().cpu())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LXYJStFnQ6Dj",
        "outputId": "ae913dac-b9e5-4abd-8ae9-ac1c69901419"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.04387942, 0.20282224, 0.5314014 , 0.03619223, 0.287428  ,\n",
              "       0.20470592, 0.00953157, 0.02502867, 0.54787314, 0.01972395,\n",
              "       0.11557244, 0.05797869, 0.00908455, 0.44626296, 0.35281157,\n",
              "       0.2079633 , 0.09165575, 0.02492141, 0.00826655, 0.05549975,\n",
              "       0.01256068, 0.00301333, 0.04330639, 0.01512295, 0.18095808,\n",
              "       0.0515527 , 0.02390566, 0.29018793, 0.7801142 , 0.21250196,\n",
              "       0.00733664, 0.00394556, 0.07715964, 0.03831826, 0.00395051,\n",
              "       0.02859649, 0.07966546, 0.04529065, 0.0204489 , 0.04158196,\n",
              "       0.86337024, 0.03547783, 0.87102807, 0.2546464 ], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for l, p in zip(LABELS, y.tolist()):\n",
        "    if p>= 0.4:\n",
        "        print(f\"{l}, {p}\")\n",
        "\n",
        "\n",
        "for i in [27925, 40687, 28689, 37771, 18398]:\n",
        "    print(movie_ori.loc[i]['제명'])\n",
        "    print(cos_similiarity(np.array(movie_ori.loc[i]['pb_emotion']),np.array(y.detach().cpu())))\n",
        "    print('---')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8is_CrJwaQO2",
        "outputId": "c869d002-bbcf-4a3d-b49d-01eb0c7308df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "감동/감탄, 0.5314013957977295\n",
            "기대감, 0.5478731393814087\n",
            "뿌듯함, 0.4462629556655884\n",
            "즐거움/신남, 0.7801141738891602\n",
            "행복, 0.8633702397346497\n",
            "기쁨, 0.8710280656814575\n",
            "명량\n",
            "0.3663338233903888\n",
            "---\n",
            "극한직업\n",
            "0.3140481055563002\n",
            "---\n",
            "인사이드 아웃\n",
            "0.663657035257374\n",
            "---\n",
            "리틀 포레스트\n",
            "0.8035442775314633\n",
            "---\n",
            "써니\n",
            "0.7397084641332972\n",
            "---\n"
          ]
        }
      ]
    }
  ]
}