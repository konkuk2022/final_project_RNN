{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "premium"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install kss"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SyV-SJvZlTO",
        "outputId": "d90c11f3-671f-435a-ba5e-0e3f7ee6f30c"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.23.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.13.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.13.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.9.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: kss in /usr/local/lib/python3.7/dist-packages (3.6.4)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.7/dist-packages (from kss) (8.14.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from kss) (2022.6.2)\n",
            "Requirement already satisfied: emoji==1.2.0 in /usr/local/lib/python3.7/dist-packages (from kss) (1.2.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBQg8vVAdKNW",
        "outputId": "dca9405d-2b97-41a7-9252-bd40b9eff66a"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn"
      ],
      "metadata": {
        "id": "u3u3P1SEYmim"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import ElectraConfig, ElectraModel\n",
        "\n",
        "\n",
        "\n",
        "class ELECTRALSTMClassification(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.device = 'cuda'\n",
        "        self.config = ElectraConfig.from_pretrained(\"beomi/KcELECTRA-base\",\n",
        "                                                    problem_type=\"multi_label_classification\",\n",
        "                                                    num_labels = 44) \n",
        "        \n",
        "        self.embedding_size = 768\n",
        "        self.batch_size = 32\n",
        "\n",
        "        self.electra = ElectraModel.from_pretrained(\"beomi/KcELECTRA-base\",config=self.config).to(self.device)\n",
        "        self.lstm = nn.LSTM(self.embedding_size, self.embedding_size, batch_first=True, bidirectional=True).to(self.device)\n",
        "        self.fc1 = nn.Linear(self.embedding_size * 5, 44)\n",
        "        self.fc2 = nn.Linear(self.embedding_size * 2, 44)\n",
        "        self.gelu = nn.GELU()\n",
        "\n",
        "\n",
        "    def forward(self, input_ids=None, attention_mask=None, sep_idx=None):\n",
        "        \n",
        "        electra_output = self.electra(input_ids, attention_mask)[0]\n",
        "\n",
        "        cls = electra_output[:, 0, :] # <CLS> embeddings\n",
        "        # sep 토큰 가져오기\n",
        "        sep_idx_x = sep_idx[0]\n",
        "        sep_idx_y = sep_idx[1]\n",
        "\n",
        "        idx = 0\n",
        "        cnt = 0\n",
        "        longest = torch.where(sep_idx_x==torch.mode(sep_idx_x).values)[0].size()[0]\n",
        "        # 초기화\n",
        "        sep_embeddings = torch.zeros(cls.size(0), longest, self.embedding_size).to(self.device)\n",
        "\n",
        "        # embedding 값 집어넣어주기\n",
        "        for x, y in zip(sep_idx_x, sep_idx_y):\n",
        "            if idx == x:\n",
        "                sep_embeddings[x, cnt, :] += electra_output[x, y, :]\n",
        "                cnt += 1\n",
        "            else:\n",
        "                idx += 1\n",
        "                cnt = 0\n",
        "                sep_embeddings[x, cnt, :] += electra_output[x, y, :]\n",
        "\n",
        "\n",
        "        # lstm 실행\n",
        "        lstm_output, (h, c) = self.lstm(sep_embeddings) # (batch_size, seq_length, embedding_size)\n",
        "\n",
        "        # lstm 처음과 끝 가져오기\n",
        "        sep_first = lstm_output[:, 0, :]\n",
        "        sep_last = lstm_output[:, -1, :]\n",
        "\n",
        "        # lstm 결과와 cls 토큰 합치기\n",
        "        concats = torch.cat((cls, sep_first, sep_last), dim=1)\n",
        "        # fc 레이어에 넣고 44개 output\n",
        "        x = self.gelu(concats)\n",
        "        output = self.fc1(x)\n",
        "\n",
        "        first_output = self.fc2(sep_first)\n",
        "        last_output = self.fc2(sep_last)\n",
        "\n",
        "        \n",
        "        return output, first_output, last_output"
      ],
      "metadata": {
        "id": "RaczW4EDZj7o"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cos_similiarity(v1, v2):\n",
        "    dot_product = np.dot(v1, v2)\n",
        "    l2_norm = (np.sqrt(sum(np.square(v1)))*np.sqrt(sum(np.square(v2))))\n",
        "    similarity = dot_product/l2_norm\n",
        "\n",
        "    return similarity"
      ],
      "metadata": {
        "id": "yGkMIKv1cEdy"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import kss\n",
        "\n",
        "def kss_sentence(sent):\n",
        "    x = ''\n",
        "    split_sent = kss.split_sentences(sent)\n",
        "    for i,s in enumerate(split_sent):\n",
        "        if i == 0:\n",
        "            x = s\n",
        "        else:\n",
        "            x += ' [SEP] ' + s\n",
        "    return x"
      ],
      "metadata": {
        "id": "x0sNGR8Vdrpa"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained('beomi/KcELECTRA-base', do_lower_case=False)\n",
        "\n",
        "def embedding(text):\n",
        "    embeddings = tokenizer(text,\n",
        "                           truncation=True,\n",
        "                           max_length=512,\n",
        "                           padding=\"max_length\",\n",
        "                           return_token_type_ids=False,\n",
        "                           return_attention_mask=True,\n",
        "                           add_special_tokens=True)\n",
        "    return embeddings"
      ],
      "metadata": {
        "id": "J6RPeo9tkIsX"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dic_ori = \"졸업식이 취소되어서 너무 아쉽다. 취소 이유는 중국 우한에서 처음 발병한 신종 코로나 바이러스 때문이다. 인생 마지막 졸업식인데 이렇게 취소가 되어버리다니 너무 허무하다. 사실은 졸업식에 별로 가고 싶지 않았다. 강의실에 우르르 모여 앉아 형식적인 학생회장의 말을 듣고, 그저 강의하는 사람 그 이상 그 이하도 아니었던 교수님들과 어색한 포옹을 하고 악수를 하며 학위기를 받는 그 상황이 너무 민망하고 어색할 것 같아서 가고 싶은 마음이 없었다. 그러다 마음을 바꾸게 된 건 우리 엄마의 부탁 때문이었다. 원래대로라면 2년 전에 이미 졸업을 했었어야 하지만 휴학, 유예 등으로 졸업이 2년이나 밀렸다. 2년을 기다려주시고, 이제 50대가 된 우리 엄마가 '더 늙기 전에 학사모 쓰고 사진 찍고 싶어!'라며 귀여운 부탁을 했다. 끝까지 거절하려다가 정말 얼마전에 엄마한테 졸업식 가자고 말씀드렸고, 엄마도 졸업식 날에 맞춰 연차까지 쓰셨지만 타이밍도 참. 속상하다. 팔정도에 있는 코끼리는 졸업식 때에만 올라탈 수 있다는 소문이 있다. 처음엔 갈 생각 없었던 졸업식이지만, 갈 마음을 먹고 나니 학사모 쓰고 코끼리 올라 탈 생각에 설레었는데 졸업식이 아예 취소가 되어버리니까 아쉬운 마음이 드는 건 왜일까? 8월에 있을 가을 학위수여식과 함께 진행한다고 하는데, 어느 누가 그 때를 기억하고 가겠어. 나는 괜찮은데, 엄마가 너무 아쉬워해서 마음이 쓰인다. 대학 입학부터 졸업까지 아무탈 없이, 걱정 없이 학교 생활 할 수 있게 도와주신 부모님께 졸업식 날에 맞춰서 꽃다발 선물이라도 해드려야겠다는 생각을 했다. 부모님 덕분에 좋은 학교 다니며, 더 멋진 사람으로 성장할 수 있게 도와주신 것에 대한 감사의 표현을 하는 것은 당연한 것 아닌가? '조금만 더 열심히 할 걸' 아쉬움이 남는 4년의 학교생활이었지만, 부모님 곁을 떠나 처음으로 타지에서 혼자 생활을 해보는 것부터 시작해서 처음 경험해볼 수 있었던 것들이 많아 행복했다. 물론 행복만 한 건 아니었지만, 대학 생활이 좋은 기억으로만 남지는 않겠지만, 그래도 소중했던 4년의 시간 덕분에 스스로 성장할 수 있었다.\"\n",
        "dic_data = kss_sentence(dic_ori)\n",
        "\n",
        "\n",
        "movie_path = '/content/drive/MyDrive/final_project/영화데이터.xlsx'\n",
        "\n",
        "movie_ori = pd.read_excel(movie_path)\n",
        "\n",
        "movie_data = []\n",
        "for n in range(10):\n",
        "    movie_data.append(kss_sentence(movie_ori['줄거리'][n]))\n",
        "\n",
        "dic_emb = embedding(dic_data)\n",
        "\n",
        "movie_emb = []\n",
        "for i in range(10):\n",
        "    movie_emb.append(embedding(movie_data[i]))"
      ],
      "metadata": {
        "id": "bMWnLmrNa8m2"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = '/content/drive/MyDrive/final_project/best_model.pth'\n",
        "\n",
        "model = ELECTRALSTMClassification()\n",
        "model.load_state_dict(torch.load(PATH),strict=False)\n",
        "model.to('cuda')\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P9usH2u9Z_nb",
        "outputId": "3e747a02-6d81-4b47-f4dd-2272cc7fdbf2"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at beomi/KcELECTRA-base were not used when initializing ElectraModel: ['discriminator_predictions.dense.bias', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense_prediction.weight']\n",
            "- This IS expected if you are initializing ElectraModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing ElectraModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ELECTRALSTMClassification(\n",
              "  (electra): ElectraModel(\n",
              "    (embeddings): ElectraEmbeddings(\n",
              "      (word_embeddings): Embedding(50135, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): ElectraEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): ElectraLayer(\n",
              "          (attention): ElectraAttention(\n",
              "            (self): ElectraSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): ElectraSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): ElectraIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): ElectraOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (lstm): LSTM(768, 768, batch_first=True, bidirectional=True)\n",
              "  (fc1): Linear(in_features=3840, out_features=44, bias=True)\n",
              "  (fc2): Linear(in_features=1536, out_features=44, bias=True)\n",
              "  (gelu): GELU(approximate=none)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_id = torch.LongTensor(dic_emb['input_ids']).unsqueeze(0).to('cuda')\n",
        "mask = torch.LongTensor(dic_emb['attention_mask']).unsqueeze(0).to('cuda')\n",
        "sep_idx = torch.where(input_id == 3)\n",
        " \n",
        "y_pred = model(input_id, mask, sep_idx)"
      ],
      "metadata": {
        "id": "2Uy1uV0do9n0"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(44):\n",
        "    print(y_pred[0].to('cpu').tolist()[0][i])\n",
        "    if y_pred[0].to('cpu').tolist()[0][i] >= 0.3:\n",
        "        print(i)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srsjRkSxtXbd",
        "outputId": "88b2fa74-5223-4094-e717-3ca2c67cde24"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-0.04543263837695122\n",
            "-0.0105989845469594\n",
            "0.030848342925310135\n",
            "-0.004434601403772831\n",
            "-0.06430709362030029\n",
            "-0.09149645268917084\n",
            "0.09236409515142441\n",
            "-0.030949797481298447\n",
            "0.02501162514090538\n",
            "0.02429257333278656\n",
            "-0.0008861669339239597\n",
            "0.05687211453914642\n",
            "0.016009172424674034\n",
            "-0.024489164352416992\n",
            "0.1302417516708374\n",
            "-0.06370110809803009\n",
            "-0.11530178785324097\n",
            "0.034983981400728226\n",
            "0.058630917221307755\n",
            "-0.015609865076839924\n",
            "-0.021420519798994064\n",
            "0.006686437409371138\n",
            "-0.08734215050935745\n",
            "-0.03961938992142677\n",
            "0.08860105276107788\n",
            "0.027330301702022552\n",
            "-0.012510018423199654\n",
            "0.08345218747854233\n",
            "0.039134759455919266\n",
            "-0.07578951120376587\n",
            "-0.06853248178958893\n",
            "0.04582741856575012\n",
            "-0.05140140280127525\n",
            "-0.04644513130187988\n",
            "-0.013921678066253662\n",
            "-0.009487727656960487\n",
            "-0.06807570159435272\n",
            "-0.03653861582279205\n",
            "-0.057973865419626236\n",
            "-0.0006428617052733898\n",
            "0.0108445193618536\n",
            "0.036166682839393616\n",
            "0.030680039897561073\n",
            "0.057493049651384354\n"
          ]
        }
      ]
    }
  ]
}